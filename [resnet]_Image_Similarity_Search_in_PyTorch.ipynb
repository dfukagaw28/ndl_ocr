{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nakamura196/ndl_ocr/blob/main/%5Bresnet%5D_Image_Similarity_Search_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9-HrzSxpLpF"
      },
      "source": [
        "#  Image Similarity Search with PyTorch and ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv7Z0_HSMSg7"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkmZSMB255IW"
      },
      "outputs": [],
      "source": [
        "HOME_DIR = \"/content\"\n",
        "IMG_DIR = \"/content/dataset\"\n",
        "# IMG_RESIZE_SIZE = 256\n",
        "IMG_RESIZE_SIZE = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOzPbzNx4wqZ"
      },
      "source": [
        "`dataset`フォルダがない場合には、データをダウンロード\n",
        "\n",
        "サンプルデータとして、以下のデータを使用させていただきます。\n",
        "\n",
        "https://idealo.github.io/imageatm/examples/cats_and_dogs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRsVq-2BuMPp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.path.exists(IMG_DIR):\n",
        "  !wget --no-check-certificate \\\n",
        "      https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "      -O cats_and_dogs_filtered.zip\n",
        "  !unzip -q cats_and_dogs_filtered.zip\n",
        "  !mkdir dataset\n",
        "\n",
        "  import glob\n",
        "  from tqdm import tqdm\n",
        "  files = glob.glob(\"/content/cats_and_dogs_filtered/*/*/*.jpg\")\n",
        "  for file in tqdm(files):\n",
        "    filename = file.split(\"/\")[-1]\n",
        "    !mv $file $IMG_DIR/$filename\n",
        "\n",
        "  !rm -rf cats_and_dogs_filtered*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ベクトル化"
      ],
      "metadata": {
        "id": "1XSokGmrBcJx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t0EdUSRMiv0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import optim, nn\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models import ResNet152_Weights\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "# Initialize the model\n",
        "model_ft = models.resnet152(weights=ResNet152_Weights.DEFAULT)\n",
        "# model_ft = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "feature_extractor = torch.nn.Sequential(*list(model_ft.children())[:-1])\n",
        "\n",
        "# Change the device to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "feature_extractor = feature_extractor.to(device)\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Transform the image, so it becomes readable with the model\n",
        "transform = transforms.Compose([\n",
        "  transforms.ToPILImage(),\n",
        "  transforms.Resize((IMG_RESIZE_SIZE, IMG_RESIZE_SIZE)),\n",
        "  transforms.ToTensor()                              \n",
        "])\n",
        "\n",
        "def getVector(path):\n",
        "  img = cv2.imread(path)\n",
        "  # Transform the image\n",
        "  img = transform(img)\n",
        "  img = img.reshape(1, 3, IMG_RESIZE_SIZE, IMG_RESIZE_SIZE)\n",
        "\n",
        "  img = img.to(device)\n",
        "  # We only extract features, so we don't need gradient\n",
        "  with torch.no_grad():\n",
        "    # Extract the feature from the image\n",
        "    feature = feature_extractor(img)\n",
        "  # Convert to NumPy Array, Reshape it, and save it to features variable\n",
        "\n",
        "  v = feature.cpu().detach().numpy().reshape(-1)\n",
        "\n",
        "  return v\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Will contain the feature\n",
        "features = []\n",
        "\n",
        "mappings = {}\n",
        "\n",
        "import glob\n",
        "files = glob.glob(f\"{IMG_DIR}/*.jpg\")\n",
        "\n",
        "files.sort()\n",
        "\n",
        "for index in tqdm(range(len(files))):\n",
        "\n",
        "  path = files[index]\n",
        "\n",
        "  filename = path.split(\"/\")[-1]\n",
        "\n",
        "  v_path = f\"data/{filename}\"\n",
        "\n",
        "  if True or not os.path.exists(v_path+\".npy\"):\n",
        "    v = getVector(path)\n",
        "    \n",
        "    os.makedirs(os.path.dirname(v_path), exist_ok=True)\n",
        "\n",
        "    np.save(v_path, v)\n",
        "\n",
        "  v = np.load(v_path+\".npy\")\n",
        "  features.append(v)\n",
        "\n",
        "  mappings[index] = {\n",
        "      \"nconst\": os.path.splitext(os.path.basename(path))[0],\n",
        "      \"name\": \"\",\n",
        "      \"url\": \"\"\n",
        "  }\n",
        "\n",
        "# mapping結果の保存\n",
        "\n",
        "import json\n",
        "\n",
        "with open('mappings.json', mode='wt', encoding='utf-8') as file:\n",
        "  json.dump(mappings, file, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "sqQkHBiY9Xzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "indexの構築"
      ],
      "metadata": {
        "id": "RdI3HEgd-BoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy"
      ],
      "metadata": {
        "id": "d_bTx-IT-sG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to NumPy Array\n",
        "features = np.array(features)\n",
        "\n",
        "N_TREES = 1000\n",
        "\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "dims = features.shape[1]\n",
        "\n",
        "print(\"dims\", dims)\n",
        "\n",
        "annoy_index = AnnoyIndex(dims, metric='angular')\n",
        "\n",
        "for i in range(len(features)):\n",
        "\n",
        "    feature = features[i]\n",
        "\n",
        "    annoy_index.add_item(i, feature)\n",
        "\n",
        "# k-d tree をビルドする\n",
        "annoy_index.build(n_trees=N_TREES)\n",
        "\n",
        "annoy_index.save(\"index.ann\")"
      ],
      "metadata": {
        "id": "gb2N_4cm9_jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 推論"
      ],
      "metadata": {
        "id": "Pqm3WGU0-E9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_matches = 10\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_similar_images(TEST_IMAGE_PATH):\n",
        "    v = getVector(TEST_IMAGE_PATH)\n",
        "    results = annoy_index.get_nns_by_vector(v, n_matches, include_distances=True)\n",
        "\n",
        "    indices = results[0]\n",
        "    scores = results[1]\n",
        "\n",
        "    for i in range(len(indices)):\n",
        "        index = indices[i]\n",
        "\n",
        "        mapping = mappings[index]\n",
        "\n",
        "        img_name = mapping[\"nconst\"] + \".jpg\"\n",
        "        img_path = os.path.join(f\"{IMG_DIR}/{img_name}\")\n",
        "        print(\"-------------------------------------------------------------------\")\n",
        "        print(img_path)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        plt.imshow(img)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "hZO7XcxF_oua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvBDBZ614qTZ"
      },
      "source": [
        "猫の例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeN-ztpA4fs8"
      },
      "outputs": [],
      "source": [
        "TEST_IMAGE_PATH = \"/content/dataset/cat.0.jpg\"\n",
        "plot_similar_images(TEST_IMAGE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGdq2a9d4nGA"
      },
      "source": [
        "犬の例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFBXusp24hqB"
      },
      "outputs": [],
      "source": [
        "TEST_IMAGE_PATH = \"/content/dataset/dog.0.jpg\"\n",
        "plot_similar_images(TEST_IMAGE_PATH)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "[resnet] Image Similarity Search in PyTorch.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyP+6MpzNlpplovmv1uvZ1g4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}